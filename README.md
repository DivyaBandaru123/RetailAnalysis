ðŸ“Š Customer Analytics Project Using Databricks & PySpark

This is the Use Case where we need to calculate the parameters according to the business requirements.

This project demonstrates how to analyze structured customer order data using PySpark in Databricks. The goal is to calculate key business metrics like total customers and prepare the dataset for weekly or monthly reporting. The dataset used (Superset.csv) is uploaded and processed in Databricks via UI-based file insertion and Spark SQL queries.

ðŸš€ Key Steps:
1. Data Loading 2. Calculation of Metrics 3. Date Automation

ðŸ“¦ Tools Used: Databricks (Community Edition), PySpark / Spark SQL, CSV Input Dataset, Temporary Views for Querying, Python (datetime, timedelta)

âœ… Project Outcomes:

1. Automated Weekly and Monthly Reporting Logic: Implemented dynamic date filters using Python and Spark to auto-calculate weekly and monthly ranges based on order_date.

2. Improved Stakeholder Accessibility: Enabled business users to easily filter and view customer metrics by time period (weekly/monthly), reducing manual effort and improving decision-making speed.
